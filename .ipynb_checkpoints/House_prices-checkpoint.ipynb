{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.model_selection._search import GridSearchCV\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"houses_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5001 entries, 0 to 5000\n",
      "Data columns (total 14 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Unnamed: 0      5001 non-null   int64  \n",
      " 1   price           5001 non-null   float64\n",
      " 2   condition       5001 non-null   object \n",
      " 3   district        5001 non-null   object \n",
      " 4   max_floor       5001 non-null   int64  \n",
      " 5   street          5001 non-null   object \n",
      " 6   num_rooms       5001 non-null   int64  \n",
      " 7   region          5001 non-null   object \n",
      " 8   area            5001 non-null   float64\n",
      " 9   url             5001 non-null   object \n",
      " 10  num_bathrooms   5001 non-null   int64  \n",
      " 11  building_type   5001 non-null   object \n",
      " 12  floor           5001 non-null   int64  \n",
      " 13  ceiling_height  5001 non-null   float64\n",
      "dtypes: float64(3), int64(5), object(6)\n",
      "memory usage: 547.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ...\n",
    "# todo: try to save the model, so that they will just upload it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sona/SH/ML/DL/venv/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.307e+11, tolerance: 1.098e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/sona/SH/ML/DL/venv/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.395e+11, tolerance: 1.046e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/sona/SH/ML/DL/venv/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.225e+11, tolerance: 1.109e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/sona/SH/ML/DL/venv/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.725e+11, tolerance: 1.085e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/sona/SH/ML/DL/venv/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.488e+11, tolerance: 1.106e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/sona/SH/ML/DL/venv/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.309e+11, tolerance: 1.098e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/sona/SH/ML/DL/venv/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.351e+11, tolerance: 1.046e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/sona/SH/ML/DL/venv/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.342e+11, tolerance: 1.109e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/sona/SH/ML/DL/venv/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.215e+11, tolerance: 1.085e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/sona/SH/ML/DL/venv/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.467e+11, tolerance: 1.106e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/sona/SH/ML/DL/venv/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.371e+11, tolerance: 1.098e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/sona/SH/ML/DL/venv/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.323e+11, tolerance: 1.046e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/sona/SH/ML/DL/venv/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.450e+11, tolerance: 1.109e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/sona/SH/ML/DL/venv/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.184e+11, tolerance: 1.085e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/sona/SH/ML/DL/venv/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.473e+11, tolerance: 1.106e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/sona/SH/ML/DL/venv/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.434e+11, tolerance: 1.098e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/sona/SH/ML/DL/venv/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.036e+10, tolerance: 1.046e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/sona/SH/ML/DL/venv/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.647e+11, tolerance: 1.109e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/sona/SH/ML/DL/venv/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.196e+11, tolerance: 1.085e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "y = df.price.to_numpy()\n",
    "df = df.drop([\"url\", \"price\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df[\"Unnamed: 0\"].replace(to_replace=df[\"Unnamed: 0\"].to_numpy(), value=1, inplace=True)\n",
    "X = pd.get_dummies(df)\n",
    "X = X.to_numpy()\n",
    "X, y = shuffle(X, y, random_state=78)\n",
    "# todo: ask what was the diff of alphabetical dummies vs not, in test and in train can differ the order of the columns so be careful to order them alphabetically, add those that don't exist in train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "lasso = Lasso(alpha=4.9)\n",
    "params = {\n",
    "    \"alpha\": [\n",
    "        # 1e-5,\n",
    "        # 1e-4,\n",
    "        # 1e-3,\n",
    "        # 1e-2,\n",
    "        # 0.1,\n",
    "        # 0.2,\n",
    "        # 0.3,\n",
    "        # 0.4,\n",
    "        # 0.5,\n",
    "        # 1,\n",
    "        # 2,\n",
    "        # 3,\n",
    "        # 4,\n",
    "        4.5,\n",
    "        4.6,\n",
    "        4.7,\n",
    "        4.8,\n",
    "        4.9,\n",
    "        5,\n",
    "        5.1,\n",
    "        5.2,\n",
    "        5.3,\n",
    "        5.4,\n",
    "        5.5,\n",
    "        # 10,\n",
    "        # 20,\n",
    "        # 30,\n",
    "        # 40,\n",
    "        # 50,\n",
    "        # 100,\n",
    "        # 200,\n",
    "        # 300,\n",
    "        # 400,\n",
    "        # 500,\n",
    "    ]\n",
    "}\n",
    "\n",
    "# RMSE: <25000 <30000, <20000 - extra hard\n",
    "# Regressor = GridSearchCV(lasso, params, scoring=\"neg_mean_squared_error\", cv=5)\n",
    "# Regressor.fit(X, y)\n",
    "# print(\"best parameter: \", Regressor.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# scaler = StandardScaler().fit(X)\n",
    "# scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=78)\n",
    "\n",
    "lasso.fit(X_train, y_train)\n",
    "y_pred = lasso.predict(X_test)\n",
    "\n",
    "print(\"RMSE before dropping features with 0 bettas: \", np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "print(\"R2 score before dropping features with 0 bettas: \", lasso.score(X_test, y_test))\n",
    "\n",
    "coefs = lasso.coef_\n",
    "\n",
    "indices_to_drop = []\n",
    "for ind in range(len(coefs)):\n",
    "    if coefs[ind] == 0 and ind != 0:\n",
    "        indices_to_drop.append(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "X_copy = np.delete(X, indices_to_drop, 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_copy, y, test_size=0.2, random_state=78)\n",
    "lasso.fit(X_train, y_train)\n",
    "lasso.predict(X_test)\n",
    "coefs = lasso.coef_\n",
    "\n",
    "\n",
    "print(\"RMSE after dropping features with 0 bettas: \", np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "print(\"R2 score after dropping features with 0 bettas: \", lasso.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# X = X_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "ridge = Ridge(alpha=1)\n",
    "params = {\n",
    "    \"alpha\": [\n",
    "        # 1e-5,\n",
    "        # 1e-4,\n",
    "        # 1e-3,\n",
    "        # 1e-2,\n",
    "        # 0.1,\n",
    "        # 0.2,\n",
    "        # 0.3,\n",
    "        # 0.4,\n",
    "        0.5,\n",
    "        0.6,\n",
    "        0.7,\n",
    "        0.8,\n",
    "        0.9,\n",
    "        1,\n",
    "        1.1,\n",
    "        1.2,\n",
    "        1.3,\n",
    "        1.4,\n",
    "        1.5\n",
    "        # 2,\n",
    "        # 3,\n",
    "        # 4,\n",
    "        # 5,\n",
    "        # 10,\n",
    "        # 20,\n",
    "        # 30,\n",
    "        # 40,\n",
    "        # 50,\n",
    "        # 100,\n",
    "        # 200,\n",
    "        # 300,\n",
    "        # 400,\n",
    "        # 500,\n",
    "    ]\n",
    "}\n",
    "\n",
    "# RMSE: <25000 <30000, <20000 - extra hard\n",
    "# Regressor = GridSearchCV(ridge, params, scoring=\"neg_mean_squared_error\", cv=5)\n",
    "# Regressor.fit(X, y)\n",
    "# print(\"best parameter: \", Regressor.best_params_)\n",
    "\n",
    "# with scaling - best parameter:  {'alpha': 1.4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "elastic_net = ElasticNet(alpha=0.0001, l1_ratio=1e-5)\n",
    "params = {\n",
    "    \"alpha\": [\n",
    "        0.0001,\n",
    "        # 1e-5,\n",
    "        # 1e-4,\n",
    "        # 1e-3,\n",
    "        # 1e-2,\n",
    "        # 1e-1,\n",
    "        # 1,\n",
    "        # 2,\n",
    "        # 3,\n",
    "        # 4,\n",
    "        # 5,\n",
    "        # 10,\n",
    "        # 20,\n",
    "        # 30,\n",
    "        # 40,\n",
    "        # 50,\n",
    "        # 100,\n",
    "    ],\n",
    "    \"l1_ratio\": [\n",
    "        1e-5,\n",
    "        # 1e-4,\n",
    "        # 1e-3,\n",
    "        # 1e-2,\n",
    "        # 0.1,\n",
    "        # 0.2,\n",
    "        # 0.3,\n",
    "        # 0.4,\n",
    "        # 0.5,\n",
    "        # 0.6,\n",
    "        # 0.7,\n",
    "        # 0.8,\n",
    "        # 0.9,\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Regressor = GridSearchCV(elastic_net, params, scoring=\"neg_mean_squared_error\", cv=5)\n",
    "# Regressor.fit(X, y)\n",
    "# print(Regressor.best_params_)\n",
    "# print(-Regressor.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# model = LinearRegression()\n",
    "model = lasso\n",
    "# model = ridge\n",
    "# model = elastic_net\n",
    "# model = poly\n",
    "# model = Ridge(alpha=1.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=10, shuffle=True, random_state=78)\n",
    "\n",
    "r2_scores = []\n",
    "RMSE_scores = []\n",
    "for train_indices, test_indices in cv.split(X):\n",
    "    X_train, X_test, y_train, y_test = (\n",
    "        X[train_indices],\n",
    "        X[test_indices],\n",
    "        y[train_indices],\n",
    "        y[test_indices],\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    scr = model.score(X_test, y_test)\n",
    "    r2_scores.append(scr)\n",
    "\n",
    "    RMSE_scores.append(np.sqrt(mean_squared_error(y_test, model.predict(X_test))))\n",
    "print(np.mean(r2_scores))\n",
    "print(np.mean(RMSE_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "RMSE_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# todo: remove v\n",
    "# in test value columns can have some values that do not appear in the train, also the other case some are in train though not in test, remove them just then process, also do OHE for the test data, try ridge not to have -R score on test, whichever model we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def final_predict(final_test_df):\n",
    "    # 1. preprocessing of final_test_df (scaling, one hot encoding ...)\n",
    "    # 2. make sure that columns and their order in train and test are the same\n",
    "    # 2. return predictions\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('houses_test.csv')\n",
    "# final_predict(df)\n",
    "\n",
    "# todo: try lasso with and without scaling"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
